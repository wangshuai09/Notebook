- [ç®€ä»‹](#ç®€ä»‹)
- [ç¯å¢ƒå‡†å¤‡](#ç¯å¢ƒå‡†å¤‡)
  - [pipå®‰è£…](#pipå®‰è£…)
  - [æºç ç¼–è¯‘å®‰è£…](#æºç ç¼–è¯‘å®‰è£…)
  - [å®‰è£…éªŒè¯](#å®‰è£…éªŒè¯)
  - [Cache è®¾ç½®](#cache-è®¾ç½®)
  - [ç¦»çº¿æ¨¡å¼](#ç¦»çº¿æ¨¡å¼)
    - [ç¯å¢ƒå˜é‡æ§åˆ¶](#ç¯å¢ƒå˜é‡æ§åˆ¶)
    - [æŒ‡å®šæœ¬åœ°è·¯å¾„](#æŒ‡å®šæœ¬åœ°è·¯å¾„)

### ç®€ä»‹

HuggingFace Transformers æä¾›äº†å¯ä»¥è½»æ¾åœ°ä¸‹è½½å¹¶ä¸”è®­ç»ƒå…ˆè¿›çš„é¢„è®­ç»ƒæ¨¡å‹çš„ API å’Œå·¥å…·ã€‚
è¿™äº›æ¨¡å‹æ”¯æŒä¸åŒæ¨¡æ€ä¸­çš„å¸¸è§ä»»åŠ¡ï¼Œæ¯”å¦‚ï¼š

ğŸ“ è‡ªç„¶è¯­è¨€å¤„ç†ï¼šæ–‡æœ¬åˆ†ç±»ã€å‘½åå®ä½“è¯†åˆ«ã€é—®ç­”ã€è¯­è¨€å»ºæ¨¡ã€æ‘˜è¦ã€ç¿»è¯‘ã€å¤šé¡¹é€‰æ‹©å’Œæ–‡æœ¬ç”Ÿæˆã€‚
ğŸ–¼ï¸ æœºå™¨è§†è§‰ï¼šå›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹å’Œè¯­ä¹‰åˆ†å‰²ã€‚
ğŸ—£ï¸ éŸ³é¢‘ï¼šè‡ªåŠ¨è¯­éŸ³è¯†åˆ«å’ŒéŸ³é¢‘åˆ†ç±»ã€‚
ğŸ™ å¤šæ¨¡æ€ï¼šè¡¨æ ¼é—®ç­”ã€å…‰å­¦å­—ç¬¦è¯†åˆ«ã€ä»æ‰«ææ–‡æ¡£æå–ä¿¡æ¯ã€è§†é¢‘åˆ†ç±»å’Œè§†è§‰é—®ç­”ã€‚

å®˜æ–¹ Transoformers æ”¯æŒåœ¨ PyTorchã€TensorFlowã€JAXä¸Šæ“ä½œï¼Œæ˜‡è…¾å½“å‰å·²å®Œæˆ Transformers çš„åŸç”Ÿæ”¯æŒã€‚æœ¬æ–‡æ¡£ä¼šä»‹ç»transformersçš„ç¯å¢ƒå‡†å¤‡å·¥ä½œã€‚

**å‰ç½®æ¡ä»¶ï¼šç¡®ä¿å·²å®Œæˆ [Ascend NPU ä¸¹ç‚‰æ­å»º](https://zhuanlan.zhihu.com/p/681513155)ã€‚**

### ç¯å¢ƒå‡†å¤‡

transformers æ”¯æŒpipå®‰è£…ï¼Œä¹Ÿå¯ä»¥æºç å®‰è£…ï¼Œè¿™é‡Œæ¨èpipå®‰è£…æ–¹å¼ï¼Œéœ€è¦åœ¨å‰ç½®æ¡ä»¶ä¸­å®‰è£…torchåŠtorch_npuçš„condaç¯å¢ƒä¸­è¿›è¡Œä¸‹è¿°æ“ä½œã€‚è‹¥æœªåœ¨å¯ä½¿ç”¨ `conda activate torch_npu` è¿›å…¥condaç¯å¢ƒ

#### pipå®‰è£…

```shell
pip install transformers
```

#### æºç ç¼–è¯‘å®‰è£…

æºç ç¼–è¯‘æ–¹å¼å¯ä»¥ä½¿ç”¨åˆ°ç¤¾åŒºçš„æœ€æ–°ç‰ˆæœ¬ä»£ç ï¼Œè€Œä¸æ˜¯æœ€æ–°çš„ç¨³å®šç‰ˆæœ¬ï¼Œå®‰è£…æ–¹å¼å¦‚ä¸‹
```shell
# 1.å¯ç¼–è¾‘æ¨¡å‹å®‰è£…æ–¹å¼ï¼Œå¯ç¼–è¾‘æœ¬åœ°ä»£ç å®æ—¶æ›´æ–°transformersåŒ…
git clone https://github.com/huggingface/transformers.git
cd transformers
pip install -e .

# 2.éç¼–è¾‘æ¨¡å¼å®‰è£…æ–¹å¼
pip install git+https://github.com/huggingface/transformers
```

#### å®‰è£…éªŒè¯

```shell
# éœ€æœºå™¨å…·å¤‡è¿æ¥å¤–ç½‘çš„æ¡ä»¶ï¼Œå°†ä¼šè‡ªåŠ¨ä¸‹è½½éœ€è¦çš„æ¨¡å‹
python -c "from transformers import pipeline; print(pipeline('sentiment-analysis')('I love you'))"

# æ— å¤–ç½‘æ¡ä»¶å¯ä½¿ç”¨å¦‚ä¸‹å‘½ä»¤
python -c "import transformers"
```

#### Cache è®¾ç½®
transformers è‡ªåŠ¨ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹çš„ä¿å­˜è·¯å¾„ä¸º` ~/.cache/huggingface/hub`, ç”±`TRANSFORMERS_CACHE`å˜é‡æ§åˆ¶ï¼Œå¦‚æœéœ€è¦æ›´æ”¹é»˜è®¤ä¿å­˜è·¯å¾„ï¼Œå¯é€šè¿‡ä¿®æ”¹å¦‚ä¸‹ä¸‰ä¸ªç¯å¢ƒå˜é‡å…¶ä¸­ä¸€ä¸ªæ¥æ§åˆ¶ï¼Œä¸‰ä¸ªå˜é‡çš„ä¼˜å…ˆçº§é€æ¸é™ä½ï¼Œ
  ```
  1.ç¯å¢ƒå˜é‡ï¼ˆé»˜è®¤ï¼‰: HUGGINGFACE_HUB_CACHE æˆ– TRANSFORMERS_CACHEã€‚
  2.ç¯å¢ƒå˜é‡ HF_HOMEã€‚
  3.ç¯å¢ƒå˜é‡ XDG_CACHE_HOME + /huggingfaceã€‚
  ```
ä¿®æ”¹æ–¹å¼å¦‚ä¸‹ï¼Œ
  ```shell
  # ä¸´æ—¶ä¿®æ”¹
  export HF_HOME=your_new_save_dir
  # æ°¸ä¹…ç”Ÿæ•ˆ
  echo export HF_HOME=your_new_save_dir >> ~/.bashrc
  ```


#### ç¦»çº¿æ¨¡å¼
##### ç¯å¢ƒå˜é‡æ§åˆ¶
Transformers æ”¯æŒåœ¨ç¦»çº¿ç¯å¢ƒä¸­è¿è¡Œï¼Œå¯ä»¥è®¾ç½® `TRANSFORMERS_OFFLINE=1` æ¥å¯ç”¨è¯¥è¡Œä¸ºã€‚è®¾ç½®ç¯å¢ƒå˜é‡ `HF_DATASETS_OFFLINE=1` å°† Datasets æ·»åŠ è‡³ç¦»çº¿è®­ç»ƒå·¥ä½œæµç¨‹ä¸­ã€‚

åŒæ ·è¿è¡Œå¦‚ä¸‹å‘½ä»¤ï¼Œç¦»çº¿æ¨¡å¼ä¼šä»æœ¬åœ°å¯»æ‰¾æ–‡ä»¶ï¼Œè€Œéç¦»çº¿æ¨¡å¼éœ€è¦è”ç½‘è¿›è¡Œæ¨¡å‹æ‰€éœ€æ–‡ä»¶çš„ä¸‹è½½æˆ–è€…æ›´æ–°
```
python examples/pytorch/translation/run_translation.py --model_name_or_path google-t5/t5-small --dataset_name wmt16 --dataset_config ro-en ...
```

##### æŒ‡å®šæœ¬åœ°è·¯å¾„
ç¯å¢ƒå˜é‡æ§åˆ¶ä¸»è¦æ˜¯ä»transformersé»˜è®¤ç¼“å­˜è·¯å¾„æœç´¢å·²ç¼“å­˜æ–‡ä»¶ï¼Œè¿˜æœ‰ä¸€ä¸ªæ›´çµæ´»çš„æŒ‡å®šæœ¬åœ°è·¯å¾„çš„æ–¹å¼å¯ä»¥ä½¿ç”¨ç¦»çº¿æ¨¡å‹æ–‡ä»¶ï¼Œè¿™ç§æ–¹å¼éœ€è¦æå‰ä¸‹å¥½æ–‡ä»¶ï¼Œä½¿ç”¨æ—¶æŒ‡å®šæ–‡ä»¶è·¯å¾„å³å¯ï¼Œ
æå‰ä¸‹è½½æ–‡ä»¶çš„æ–¹å¼æœ‰ä»¥ä¸‹ä¸‰ç§ï¼š
1. ç‚¹å‡»[Model Hub](https://huggingface.co/models)ç”¨æˆ·ç•Œé¢çš„â¬‡å›¾æ ‡ä¸‹è½½æ–‡ä»¶
   
   ![](https://raw.githubusercontent.com/wangshuai09/blog_img/main/images/20240606111628.png)

   å°†ä¸‹è½½åçš„æ‰€æœ‰æ–‡ä»¶æ”¾ç½®ä¸€ä¸ªè·¯å¾„ä¸‹ï¼Œä¾‹å¦‚`./your/path/bigscience_t0`
   
2. ä½¿ç”¨`PreTrainedModel.from_pretrained()`å’Œ`PreTrainedModel.save_pretrained()`å·¥ä½œæµç¨‹
    
    éœ€è¦è”ç½‘é¢„å…ˆä¸‹è½½æ¨¡å‹å¹¶ä¿å­˜ï¼Œ
      ```python
      # ä¸‹è½½æ–‡ä»¶
      >>> from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
      >>> tokenizer = AutoTokenizer.from_pretrained("bigscience/T0_3B")
      >>> model = AutoModelForSeq2SeqLM.from_pretrained("bigscience/T0_3B")
      # ä¿å­˜æ–‡ä»¶è‡³æœ¬åœ°ç›®å½•
      >>> tokenizer.save_pretrained("./your/path/bigscience_t0")
      >>> model.save_pretrained("./your/path/bigscience_t0")
      ```
    
3. ä½¿ç”¨ä»£ç ç”¨huggingface_hubåº“ä¸‹è½½æ–‡ä»¶
   
   é¦–å…ˆ,å®‰è£…`huggingface_hub`åº“
   ```python
   python -m pip install huggingface_hub
   ```
   ä¹‹å,è¿›è¡Œæ¨¡å‹ä¸‹è½½
   ```python
   >>> from huggingface_hub import hf_hub_download
   # ä¸‹è½½å•ä¸ªæ–‡ä»¶
   >>> hf_hub_download(repo_id="bigscience/T0_3B", filename="config.json", cache_dir="./your/path/bigscience_t0")
   # ä¸‹è½½æ•´ä¸ªé¡¹ç›®
   >>> from huggingface_hub import snapshot_download
   snapshot_download(repo_id="bigscience/T0_3B", cache_dir="./your/path/bigscience_t0")
   ```

ä»¥ä¸Šä¸‰ç§æ–¹å¼éƒ½éœ€è¦ç§‘å­¦ä¸Šç½‘å·¥å…·ï¼Œå¯¹äº**å›½å†…ç”¨æˆ·**è¿˜æ˜¯æ¨èä»¥ä¸‹æ–¹å¼ï¼Œ

1. ç‚¹å‡» [Hf é•œåƒç½‘ç«™](https://hf-mirror.com/)â¬‡å›¾æ ‡ä¸‹è½½æ–‡ä»¶
   ![](https://raw.githubusercontent.com/wangshuai09/blog_img/main/images/20240606112516.png)
   
2. ä¿®æ”¹huggingface_hubçš„é•œåƒæº
   é¦–å…ˆï¼Œå®‰è£…`huggingface_hub`åº“
   ```python
   python -m pip install huggingface_hub
   ```
   ä¹‹åï¼Œä¿®æ”¹ç¯å¢ƒå˜é‡`HF_ENDPOINT`,è¯¥å˜é‡ä¼šæ›¿æ¢`huggingface.co`åŸŸå
   ```shell
   # ä¸´æ—¶ç”Ÿæ•ˆ
   export HF_ENDPOINT=https://hf-mirror.com
   # æ°¸ä¹…ç”Ÿæ•ˆ
   echo export HF_ENDPOINT=https://hf-mirror.com >> ~/.bashrc
   ```
   ç°åœ¨å°±å¯ä»¥è¿›è¡Œæ¨¡å‹ä¸‹è½½äº†
   ```python
   # ä¸‹è½½å•ä¸ªæ–‡ä»¶
   >>> from huggingface_hub import hf_hub_download
   >>> hf_hub_download(repo_id="bigscience/T0_3B", filename="config.json", cache_dir="./your/path/bigscience_t0")
   # ä¸‹è½½æ•´ä¸ªé¡¹ç›®
   >>> from huggingface_hub import snapshot_download
   snapshot_download(repo_id="bigscience/T0_3B", cache_dir="./your/path/bigscience_t0")
   ```

3. git lfs
   åœ¨ [Hf é•œåƒç½‘ç«™](https://hf-mirror.com/)æ‰¾åˆ°gitä¸‹è½½è·¯å¾„
   ![](https://raw.githubusercontent.com/wangshuai09/blog_img/main/images/20240606113249.png)
   ä¹‹åæŒ‰ç…§æŒ‡ç¤ºä¸‹è½½git lfs å¹¶ä¸‹è½½æ¨¡å‹æ–‡ä»¶ï¼Œ
   ![](https://raw.githubusercontent.com/wangshuai09/blog_img/main/images/20240606113437.png)

æ¨¡å‹æ–‡ä»¶ä¸‹è½½å¥½åï¼Œä½¿ç”¨`from_pretrained`æµç¨‹è¿›è¡ŒåŠ è½½
```python
import torch 
import torch_npu
from transformers import AutoConfig

device = "npu:0"
tokenizer = AutoTokenizer.from_pretrained("./your/path/bigscience_t0")
model = AutoModel.from_pretrained("./your/path/bigscience_t0").to(device)
config = AutoConfig.from_pretrained("./your/path/bigscience_t0/config.json")
```